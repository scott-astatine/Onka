import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';

/// A service class to manage WebRTC connections, media streams, and renderers.
/// This encapsulates the core logic for a peer-to-peer video call.
class WebRTCService {
  // Private variables to hold the core WebRTC objects.
  RTCPeerConnection? _peerConnection;
  MediaStream? _localStream;
  MediaStream? _remoteStream;

  // Public renderers that the UI will use to display video.
  final RTCVideoRenderer localRenderer = RTCVideoRenderer();
  final RTCVideoRenderer remoteRenderer = RTCVideoRenderer();

  // Flag to track if the renderers have been initialized.
  bool _isInitialized = false;

  // --- Public Getters for UI State ---

  /// Provides access to the local media stream.
  MediaStream? get localStream => _localStream;

  /// A simple check to see if the local video stream is available and running.
  bool get isVideoReady =>
      _localStream != null && _localStream!.getVideoTracks().isNotEmpty;

  /// Checks if the service's renderers are initialized and ready to be used.
  bool get isInitialized => _isInitialized;

  /// Initializes the video renderers. This must be called before they can be used.
  Future<void> initRenderers() async {
    // Avoid re-initializing if already done.
    if (_isInitialized) return;

    try {
      await localRenderer.initialize();
      await remoteRenderer.initialize();
      _isInitialized = true;
      debugPrint('✅ Video renderers initialized successfully');
    } catch (e) {
      debugPrint('❌ Error initializing renderers: $e');
      _isInitialized = false;
      // Re-throw the error so the calling widget can handle it (e.g., show an error message).
      rethrow;
    }
  }

  /// Requests camera and microphone permissions and captures the local media stream.
  Future<void> getUserMedia() async {
    // Define standard media constraints for a video call.
    final Map<String, dynamic> mediaConstraints = {
      'audio': true,
      'video': {
        'facingMode': 'user',
        'mandatory': {
          'minWidth': '640',
          'minHeight': '480',
          'minFrameRate': '30',
        },
      },
    };

    try {
      // Get the media stream from the user's device.
      _localStream = await navigator.mediaDevices.getUserMedia(
        mediaConstraints,
      );
      debugPrint('✅ Local stream obtained successfully.');

      // Attach the local stream to the local video renderer to display it.
      localRenderer.srcObject = _localStream;
    } catch (e) {
      debugPrint('❌ Error getting user media: $e');
      // If getting video fails, try a fallback to an audio-only stream.
      try {
        _localStream = await navigator.mediaDevices.getUserMedia({
          'audio': true,
          'video': false,
        });
        debugPrint('✅ Fallback to audio-only stream successful.');
        localRenderer.srcObject = _localStream;
      } catch (audioError) {
        debugPrint('❌ Error getting audio-only stream: $audioError');
        // If even audio fails, re-throw the error.
        rethrow;
      }
    }
  }

  /// Creates and configures the RTCPeerConnection object.
  Future<void> initPeerConnection({
    required Map<String, dynamic> configuration,
    required Function(RTCIceCandidate candidate) onIceCandidate,
    required Function(MediaStream stream) onTrack,
  }) async {
    // Ensure any previous connection is properly closed before starting a new one.
    await _resetPeerConnection();

    _peerConnection = await createPeerConnection(configuration);

    // Listen for ICE candidates generated by the local peer.
    // These candidates must be sent to the remote peer via the signaling server.
    _peerConnection!.onIceCandidate = (candidate) {
      if (candidate != null) {
        onIceCandidate(candidate);
      }
    };

    // Listen for media tracks from the remote peer.
    _peerConnection!.onTrack = (event) {
      if (event.track.kind == 'video' && event.streams.isNotEmpty) {
        _remoteStream = event.streams[0];
        // Attach the remote stream to the remote video renderer.
        remoteRenderer.srcObject = _remoteStream;
        // Notify the UI that it needs to update.
        onTrack(event.streams[0]);
      }
    };

    // Add all tracks from our local stream to the peer connection so they can be sent.
    if (_localStream != null) {
      for (var track in _localStream!.getTracks()) {
        _peerConnection!.addTrack(track, _localStream!);
      }
      debugPrint('✅ Local tracks added to peer connection.');
    }
  }

  /// Creates an SDP offer to initiate a connection.
  Future<RTCSessionDescription> createOffer() async {
    if (_peerConnection == null)
      throw Exception('PeerConnection not initialized');
    return await _peerConnection!.createOffer();
  }

  /// Creates an SDP answer to respond to an offer.
  Future<RTCSessionDescription> createAnswer() async {
    if (_peerConnection == null)
      throw Exception('PeerConnection not initialized');
    return await _peerConnection!.createAnswer();
  }

  /// Sets the local SDP description.
  Future<void> setLocalDescription(RTCSessionDescription description) async {
    if (_peerConnection == null)
      throw Exception('PeerConnection not initialized');
    await _peerConnection!.setLocalDescription(description);
  }

  /// Sets the remote SDP description received from the other peer.
  Future<void> setRemoteDescription(RTCSessionDescription description) async {
    if (_peerConnection == null)
      throw Exception('PeerConnection not initialized');
    await _peerConnection!.setRemoteDescription(description);
  }

  /// Adds a new ICE candidate received from the remote peer.
  Future<void> addIceCandidate(RTCIceCandidate candidate) async {
    if (_peerConnection == null)
      throw Exception('PeerConnection not initialized');
    await _peerConnection!.addCandidate(candidate);
  }

  /// Safely closes and nullifies the current peer connection.
  Future<void> _resetPeerConnection() async {
    if (_peerConnection != null) {
      await _peerConnection!.close();
      _peerConnection = null;
      debugPrint('Peer connection reset.');
    }
  }

  /// Cleans up all resources used by the service.
  /// This should be called when the widget using this service is disposed.
  Future<void> close() async {
    try {
      // 1. Stop all media tracks to release camera/mic.
      _localStream?.getTracks().forEach((track) async {
        await track.stop();
      });
      _localStream?.dispose();
      _localStream = null;
      debugPrint('Local stream closed.');

      // 2. Close the peer connection.
      await _resetPeerConnection();

      // 3. Clear the video renderers' sources.
      localRenderer.srcObject = null;
      remoteRenderer.srcObject = null;
      debugPrint('Renderers cleared.');

      // 4. Dispose of the renderers to free up native resources.
      if (localRenderer.textureId != null) await localRenderer.dispose();
      if (remoteRenderer.textureId != null) await remoteRenderer.dispose();
      _isInitialized = false;
      debugPrint('Renderers disposed.');

      debugPrint('✅ WebRTC service closed successfully');
    } catch (e) {
      debugPrint('❌ Error closing WebRTC service: $e');
    }
  }
}
